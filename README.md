# Eve_Benchmark

This repository contains the code for the paper: "Benchmarking Emotion Recognition with Vision-Language Models". It introduces an evaluation of popular Vision-Language Models (VLMs) like GPT4-omni, LLaVA, LLaVA-Next, and Qwen-VL on a novel benchmark, **EvE**, for <ins>Ev</ins>oked <ins>E</ins>motion Recognition. 

The 'src' directory contains the main code for the evaluation process, which includes a dataset setup code, and the evaluation for individual models. 

